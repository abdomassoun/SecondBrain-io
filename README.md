# File Storage Service

A robust, enterprise-grade file storage service built with Laravel following Domain-Driven Design (DDD) principles. This service provides secure file upload, download, and management capabilities with JWT authentication, user-based access control, and comprehensive activity logging.

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Requirements](#-requirements)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Authentication](#-authentication)
- [Access Control](#-access-control)
- [Postman Collection](#-postman-collection)
- [File Upload Methods](#-file-upload-methods)
- [Testing](#-testing)
- [Database Schema](#-database-schema)
- [Development Flow](#-development-flow)
- [Note](#-note)

## âœ¨ Features

### Core Features
- âœ… **File Upload/Download/Delete**: Complete file lifecycle management
- âœ… **JWT Authentication**: Secure token-based authentication using `tymon/jwt-auth`
- âœ… **User Registration & Login**: Full authentication flow with password reset
- âœ… **Ownership-based Access Control**: Users can only access their own files
- âœ… **File Metadata Tracking**: ID, name, size, MIME type, upload date, owner
- âœ… **Activity Logging**: Track all file operations (upload, download, delete) with Spatie Activity Log
- âœ… **Input Validation**: Comprehensive request validation for all endpoints
- âœ… **Error Handling**: Meaningful error messages with appropriate HTTP status codes
- âœ… **Unit & Feature Tests**: Extensive test coverage using Pest PHP

### Advanced Features
- ğŸš€ **Chunked File Upload**: Support for large files with resumable chunk-based uploads
- ğŸ”’ **Idempotency Protection**: Prevents duplicate uploads of the same file
- ğŸ“ **File Type Validation**: Whitelist-based MIME type validation
- ğŸ“„ **Pagination**: Efficient handling of large file lists
- ğŸ¯ **File Filtering**: Filter files by owner and MIME type
- ğŸ“Š **Formatted File Sizes**: Human-readable file size formatting
- ğŸ” **Rate Limiting**: Throttling for auth and API endpoints
- ğŸ³ **Docker Support**: Complete Docker Compose setup with PostgreSQL
- ğŸ“ˆ **Database Indexing**: Optimized database queries with proper indexing

## ğŸ—ï¸ Architecture

This project follows **Domain-Driven Design (DDD)** principles with a clean, layered architecture:

```
app/
â”œâ”€â”€ Application/          # Application services, handlers, DTOs
â”‚   â”œâ”€â”€ Files/
â”‚   â”‚   â”œâ”€â”€ Commands/     # Command objects
â”‚   â”‚   â”œâ”€â”€ DTOs/         # Data Transfer Objects
â”‚   â”‚   â”œâ”€â”€ Handlers/     # Command/Query handlers
â”‚   â”‚   â”œâ”€â”€ Queries/      # Query objects
â”‚   â”‚   â””â”€â”€ Services/     # Application services
â”‚   â””â”€â”€ Users/
â”œâ”€â”€ Domain/              # Business logic and entities
â”‚   â”œâ”€â”€ Files/
â”‚   â”‚   â”œâ”€â”€ Entities/    # Domain entities
â”‚   â”‚   â”œâ”€â”€ Repositories/ # Repository interfaces
â”‚   â”‚   â””â”€â”€ ValueObjects/ # Value objects (MimeType, FileSize, FilePath)
â”‚   â”œâ”€â”€ Shared/          # Shared domain logic
â”‚   â””â”€â”€ Users/
â”œâ”€â”€ Infrastructure/      # External concerns
â”‚   â”œâ”€â”€ Persistence/
â”‚   â”‚   â””â”€â”€ Eloquent/    # Eloquent models and repositories
â”‚   â”œâ”€â”€ EventListeners/
â”‚   â””â”€â”€ Providers/
â””â”€â”€ Presentation/        # API layer
    â”œâ”€â”€ Http/
    â”‚   â”œâ”€â”€ Controllers/ # API controllers
    â”‚   â”œâ”€â”€ Requests/    # Form request validation
    â”‚   â””â”€â”€ Resources/   # API resources
    â””â”€â”€ CLI/
```

### Key Design Patterns
- **Repository Pattern**: Abstract data access layer
- **CQRS**: Separate command and query responsibilities
- **Value Objects**: Encapsulate domain logic (MimeType, FileSize)
- **DTOs**: Transfer data between layers
- **Service Layer**: Orchestrate business operations

## ğŸ“¦ Requirements

- PHP 8.2 or higher
- PostgreSQL 15+
- Composer
- Docker & Docker Compose (recommended)
- Node.js & npm (for asset compilation)

## ğŸš€ Installation

### Option 1: Docker (Recommended)

1. **Clone the repository**
   ```bash
   git clone https://github.com/abdomassoun/SecondBrain-io.git
   ```

2. **Start the services**
   ```bash
   docker-compose up -d
   ```
3. **Enter the application container (could also be `secondbrain-io_application_1`)**
   ```bash
   docker exec -ti secondbrain-io-application-1 bash
   ```
4. **Run the Deploy script**
   ```bash
   sh deploy.sh
   ```
## âš™ï¸ Configuration

### File Upload Limits

- **Single Upload**: 4MB (configurable in `UploadFileRequest.php`)
- **Chunk Upload**: Unlimited (chunks are merged server-side)
- **Chunk Size**: Configurable (default: 1MB in test script)

### Allowed File Types

Configured in `app/Domain/Files/ValueObjects/MimeType.php`:
- **Images**: JPEG, PNG, GIF, WebP, SVG
- **Documents**: PDF, Word, Excel, PowerPoint, Text, CSV
- **Archives**: ZIP, RAR, 7Z
- **Video**: MP4, MPEG, MOV, AVI
- **Audio**: MP3, WAV, OGG

## ğŸ” Authentication

### JWT (JSON Web Tokens)

This service uses JWT for stateless authentication:

1. **Register** or **Login** to receive a JWT token
2. Include the token in the `Authorization` header for all protected endpoints:
   ```
   Authorization: Bearer {your-jwt-token}
   ```
3. Tokens expire after 60 minutes (configurable via `JWT_TTL`)
4. Use the refresh endpoint to get a new token without re-authenticating

### Security Features

- Passwords are hashed using bcrypt
- JWT tokens are signed and verified
- Rate limiting on authentication endpoints
- Protected routes require valid authentication

## ğŸ”’ Access Control

### Ownership-based Authorization

The system implements strict ownership-based access control:

- Users can **only view, download, or delete** files they uploaded
- Attempts to access other users' files return `403 Forbidden`
- File ownership is tracked via `owner_uuid` field
- Authorization checks are performed at the service layer

## ğŸ“® Postman Collection

A complete Postman collection is included for testing all API endpoints:

**Import the collection:**
```bash
backend.postman_collection.json
```

**Environment Variables:**
- Set `{{base_url}}` to `http://localhost:8000/api/v1`

## ğŸ“¤ File Upload Methods

### 1. Simple Upload (< 4MB)

Best for small files:

```bash
curl -X POST http://localhost:8000/api/v1/files/upload \
  -H "Authorization: Bearer {token}" \
  -F "file=@/path/to/file.pdf"
```

### 2. Chunked Upload (Large Files)

For files of any size with resumable uploads:

```bash
# Use the provided test script
chmod +x test-chunked-upload.sh
./test-chunked-upload.sh /path/to/large-file.mp4
```

**Chunked Upload Process:**
1. File is split into chunks on the client
2. Each chunk is uploaded with `upload-chunk` endpoint
3. Server tracks progress in `file_chunks` table
4. Once all chunks are uploaded, call `complete-upload`
5. Server merges chunks into final file
6. Chunks are cleaned up automatically

**Benefits:**
- Support for unlimited file sizes
- Resumable uploads
- Progress tracking
- Network interruption tolerance

## ğŸ§ª Testing

### Run All Tests

```bash
# Using Docker
docker-compose exec application php artisan test

# Local
php artisan test
```

### Run Specific Test Suites

```bash
# Application tests only
php artisan test --testsuite=Application

# Domain tests only
php artisan test --testsuite=Domain

# Example: test the file module in the Application layer
php artisan test --filter files --testsuite=Application
```

## ğŸ—„ï¸ Database Schema
For detailed information, see the `database-schema.dbml` file.

## ğŸ› ï¸ Development Flow

To make the workflow faster and more organized, I follow this process:

**ğŸ§± DBML Schema (Structure & Model) â†’ âš™ï¸ Module Implementation (Controllers / Services / Business Logic) â†’ ğŸ“¬ AI Postman Update (API Docs & Testing)**
### âœ… Why this approach?

- Clear architecture before coding  
- Faster implementation with structured thinking  
- AI-friendly reference for accurate generation  
- Automatically updated API documentation  
- Better deployment readiness  

This way, I save time, keep the project well-documented, and ensure smooth deployment.

## ğŸ“ Note

I know the task was asking for a normal file upload, but I added the chunk upload part because it is closer to what happens in real-world cases, along with other improvements like idempotency.

Chunked uploads are well-suited for small to medium-sized files. For very large files, a protocol like TUS would be more appropriate. However, I intentionally did not implement TUS here to avoid unnecessary complexity and over-engineering beyond the scope of the exercise.
